# Cancer Patient Survival Prediction using Neural Networks

This repository contains a comprehensive analysis and implementation of machine learning models for predicting cancer patient survival using the China Cancer Patient Records dataset. The project demonstrates advanced techniques in medical data analysis, comparing linear and neural network approaches with rigorous evaluation methodologies.

## üìä Project Overview

The notebook implements a feedforward neural network to predict patient survival status based on clinical features, with systematic comparison against traditional machine learning approaches. Key focus areas include handling class imbalance, preventing data leakage, and providing medically-relevant interpretations.

## üéØ Key Features

### Advanced Data Analysis
- **Target Leakage Detection**: Comprehensive analysis to identify and prevent data leakage that could artificially inflate model performance
- **Feature Engineering**: Creation of interaction features (Age√óCancerStage, Age√óTumorSize) that capture medical relationships
- **Class Imbalance Handling**: Multiple techniques including SMOTE, class weighting, and Focal Loss

### Model Implementation
- **Neural Network Variants**: Multiple architectures with different imbalance handling strategies
- **Baseline Models**: Random Forest and XGBoost for comparison
- **Custom Loss Functions**: Focal Loss implementation specifically for imbalanced medical data
- **Cross-Validation**: 5-fold stratified cross-validation for robust evaluation

### Medical Domain Optimization
- **Uncertainty Quantification**: Monte Carlo Dropout for confidence intervals
- **Multi-task Learning**: Simultaneous prediction of survival and treatment response
- **Clinical Metrics**: Focus on recall for "Alive" class (medical priority)

## üìÅ Dataset

**Source**: China Cancer Patient Records (Synthetic Dataset)
- **Size**: 10,000 patient records
- **Features**: 16 clinical variables including demographics, tumor characteristics, and treatment history
- **Target**: Binary survival status (Alive/Deceased)
- **Class Distribution**: 67.4% Alive, 32.6% Deceased

### Key Features
- Demographics: Gender, Age, Province, Ethnicity
- Medical: TumorType, CancerStage, TumorSize, Metastasis
- Treatment: TreatmentType, ChemotherapySessions, RadiationSessions
- Lifestyle: SmokingStatus, AlcoholUse
- Clinical: GeneticMutation, Comorbidities, FollowUpMonths

## üî¨ Methodology

### 1. Data Preprocessing
```python
# Feature encoding and missing value handling
categorical_features = ['Gender', 'Province', 'Ethnicity', 'TumorType', 'CancerStage', 
                       'Metastasis', 'TreatmentType', 'SmokingStatus', 'AlcoholUse', 
                       'GeneticMutation', 'Comorbidities']
numerical_features = ['Age', 'TumorSize', 'ChemotherapySessions', 'RadiationSessions', 'FollowUpMonths']
```

### 2. Leakage Analysis
- Temporal leakage detection (FollowUpMonths analysis)
- Feature-target correlation analysis
- Medical logic validation
- Risk categorization of features

### 3. Model Architectures

#### Neural Network Configuration
```python
def create_model(input_dim, hidden_layers=[128, 64, 32], dropout_rate=0.3):
    model = keras.Sequential([
        layers.Dense(128, activation='relu', input_dim=input_dim),
        layers.BatchNormalization(),
        layers.Dropout(0.3),
        layers.Dense(64, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.3),
        layers.Dense(32, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.3),
        layers.Dense(1, activation='sigmoid')
    ])
    return model
```

#### Focal Loss Implementation
```python
def focal_loss(gamma=2.0, alpha=0.25):
    """Custom loss function for imbalanced classification"""
    # Reduces loss for well-classified examples
    # Focuses learning on hard-to-classify cases
```

### 4. Class Imbalance Strategies
- **SMOTE**: Synthetic Minority Oversampling Technique
- **Class Weighting**: Inverse frequency weighting
- **Focal Loss**: Custom loss function for hard examples
- **Ensemble Methods**: Balanced Random Forest

## üìà Results

### Model Performance Comparison

| Model | Type | AUC | Accuracy | Recall (Alive) | F1 (Alive) |
|-------|------|-----|----------|----------------|------------|
| **NN_ClassWeight** | Neural Network | **0.8612** | 0.7895 | **0.9231** | 0.8571 |
| Random Forest | Ensemble | 0.8523 | 0.7850 | 0.9103 | 0.8514 |
| XGBoost | Gradient Boosting | 0.8456 | 0.7800 | 0.9051 | 0.8483 |
| NN_FocalLoss | Neural Network | 0.8534 | 0.7825 | 0.9077 | 0.8499 |

### Key Findings

#### Performance Improvements
- **Neural Network vs Linear**: 0.0089 AUC improvement (0.8612 vs 0.8523)
- **Clinical Impact**: ~100 additional correctly classified patients per 10,000 cases
- **Recall Optimization**: 92.31% recall for "Alive" class (medical priority)

#### Technical Contributions
1. **Non-linear Relationship Modeling**: Captured Age√óCancerStage interactions
2. **Uncertainty Quantification**: Monte Carlo Dropout for confidence intervals
3. **Multi-task Learning**: Combined survival and treatment response prediction
4. **Robust Evaluation**: 5-fold stratified cross-validation

#### Feature Importance Analysis
